<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>UW Institute on the Algorithmic Foundations of Data Science</title>
    <description></description>
    <link>http://localhost:4000/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Yin Tat Lee (coPI) named 2020 Sloan Research Fellows</title>
        <description>&lt;p&gt;We are very happy to announce that Yin Tat Lee (ADSI coPI) have been named 2020 Sloan Research Fellows by the Alfred P. Sloan Foundation. The program recognizes early-career scientists in the United States and Canada who are nominated and judged by their peers based on their creativity, leadership, and achievements in research. More details can be found in the Allen School news &lt;a href=&quot;https://news.cs.washington.edu/2020/02/12/hannaneh-hajishirzi-and-yin-tat-lee-named-2020-sloan-research-fellows/&quot;&gt;post&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Wed, 12 Feb 2020 00:00:00 -0800</pubDate>
        <link>/news/2020/02/12/sloan/</link>
        <guid isPermaLink="true">/news/2020/02/12/sloan/</guid>
      </item>
    
      <item>
        <title>Corinne Jones won the ASA Statistical Computing Award</title>
        <description>&lt;p&gt;Corinne Jones won the 2020 Chambers Student Paper Award from the ASA Statistical Computing Section, for her paper “End-to-end Learning,
with or without Labels” (&lt;a href=&quot;https://arxiv.org/abs/1912.12979&quot;&gt;arxiv report&lt;/a&gt;; &lt;a href=&quot;https://github.com/cjones6/xsdc&quot;&gt;github repository&lt;/a&gt;).&lt;/p&gt;
</description>
        <pubDate>Fri, 17 Jan 2020 00:00:00 -0800</pubDate>
        <link>/news/2020/01/17/Corinne-Jones/</link>
        <guid isPermaLink="true">/news/2020/01/17/Corinne-Jones/</guid>
      </item>
    
      <item>
        <title>Talk Announcement</title>
        <description>&lt;p&gt;Steffen will be visiting From Jan 21 to Feb 1 as part of the ADSI Visiting Faculty Program. He will be sitting in the ADSI faculty office, room CSE2 315. During his visit, Steffen will be giving a ML lunch seminar on Thurs Jan 23rd at noon. The details are follows:&lt;/p&gt;

&lt;p&gt;Title:
Oblivious data for kernel methods&lt;/p&gt;

&lt;p&gt;Abstract:
I’ll present an approach to reduce the influence of sensitive features in data in the context of kernel methods. The resulting method uses Hilbert space valued conditional expectations to create new features that are close approximations of the original (non-sensitive) features while having a reduced dependence on the sensitive features. I’ll provide optimality statements about these new features and a bound on the alpha-mixing coefficient between the sensitive features and these new features. In practice, standard techniques to estimate conditional expectations can be used to generate these features. I’ll discuss a plug-in approach for estimating conditional expectation which uses properties of the empirical process to control estimation errors.&lt;/p&gt;

&lt;p&gt;Short bio:
Steffen is an assistant professor in the department of mathematics and statistics at Lancaster University, UK. He joined the department in autumn 2014. His main area of research is large-scale machine learning with a focus on the interplay of kernel methods, convex optimization in Hilbert spaces and empirical process theory. Prior to joining Lancaster University, Steffen was a postdoctoral researcher in computer science at University College London. He completed his PhD in machine learning at the Technical University Berlin.&lt;/p&gt;

</description>
        <pubDate>Fri, 03 Jan 2020 00:00:00 -0800</pubDate>
        <link>/news/2020/01/03/SteffenGrunewalder/</link>
        <guid isPermaLink="true">/news/2020/01/03/SteffenGrunewalder/</guid>
      </item>
    
      <item>
        <title>&lt;a href='https://www.ece.uw.edu/spotlight/lytle2019/'&gt;Talk Announcement&lt;/a&gt;</title>
        <description>
</description>
        <pubDate>Wed, 27 Nov 2019 00:00:00 -0800</pubDate>
        <link>/news/2019/11/27/Stephane_Mallat/</link>
        <guid isPermaLink="true">/news/2019/11/27/Stephane_Mallat/</guid>
      </item>
    
      <item>
        <title>&lt;a href='https://blogs.uw.edu/tops/marco-cuturi-computational-optimal-transport/'&gt;Talk Announcement&lt;/a&gt;</title>
        <description>
</description>
        <pubDate>Sat, 16 Nov 2019 00:00:00 -0800</pubDate>
        <link>/news/2019/11/16/Cuturi_Core/</link>
        <guid isPermaLink="true">/news/2019/11/16/Cuturi_Core/</guid>
      </item>
    
      <item>
        <title>Promotion News</title>
        <description>&lt;p&gt;Dmitriy Drusvyatskiy (Math), Zaid Harchaoui (Statistics) have been promoted to Associate Professor and Maryam Fazel (ECE) has been promoted to full Professor.&lt;/p&gt;
</description>
        <pubDate>Fri, 11 Oct 2019 00:00:00 -0700</pubDate>
        <link>/news/2019/10/11/promotion/</link>
        <guid isPermaLink="true">/news/2019/10/11/promotion/</guid>
      </item>
    
      <item>
        <title>Dmitriy Drusvyatskiy receives the INFORMS Young Researcher Prize</title>
        <description>&lt;p&gt;Dmitriy Drusvyatskiy and Damek Davis (Cornell) are the joint recipients of the 2019 INFORMS Optimization Society Prize for Young Researchers for their outstanding paper in optimization (details forthcoming). This prize serves as an esteemed recognition of promising colleagues who are at the beginning of their academic or industrial career.&lt;/p&gt;

&lt;p&gt;More details can be found &lt;a href=&quot;https://math.washington.edu/news/2019/09/30/dmitriy-drusvyatskiy-receives-informs-young-researcher-prize&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Fri, 11 Oct 2019 00:00:00 -0700</pubDate>
        <link>/news/2019/10/11/Dima-INFORMS/</link>
        <guid isPermaLink="true">/news/2019/10/11/Dima-INFORMS/</guid>
      </item>
    
      <item>
        <title>Summer Workshop on Algorithmic Foundations of Learning and Control</title>
        <description>&lt;center&gt;&lt;img src=&quot;http://ads-institute.uw.edu/images/workshop.jpg&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;a href=&quot;https://ajwagen.github.io/adsi_learning_and_control/&quot;&gt;The ADSI Summer Workshop on Algorithmic Foundations of Learning and Control&lt;/a&gt; was organized by UW and U Wisconsin over 2.5 days (August 19-21), held on the UW Campus.&lt;/p&gt;

&lt;p&gt;The workshop provided a forum to discuss timely topics bridging the different research communities: the statistical and reinforcement learning community, the optimization and control theory community, as well as robotics practitioners. The event brought together researchers with diverse backgrounds in computer science, control theory, statistics and math, to discuss theoretical and foundational questions arising from dynamical systems that aim to learn from, and take action in, their environments (such as robotic systems that perform manipulation and navigation).&lt;/p&gt;

&lt;p&gt;The format included five 45-minute talks per day (and 3 on the last day), with breaks for discussion, as well as two panel sessions where the speakers of each day formed a panel and debated questions raised by the audience. The timely and exciting intersection of fields, and the carefully chosen list of speakers, contributed to lively debates and discussions about different viewpoints. For example, one of the talks (on online learning and control of linear dynamical systems) motivated discussions about how the theoretical computer science community and the control theory community use different terminology for similar concepts, and how to progress towards connecting these disciplines better and providing a common language to address contemporary challenges in learning and artificial intelligence.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;float: right; width:50%;&quot; src=&quot;http://ads-institute.uw.edu/images/workshop2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speakers included Todorov, Boots (UW), Parrilo (MIT), Recht (UC Berkeley), Szepesvari (U Alberta &amp;amp; Google), Kumar (Google Brian), Brunskill, Ye (Stanford), Russo (Columbia), Wang (Princeton), Ozay (Michigan), Mansour (Tel Aviv University), Agarwal (Microsoft Research).&lt;/p&gt;

&lt;p&gt;The summer school was made possible by support from National Science Foundation. The program was organized by Maryam Fazel, Kevin Jamieson, and Sham Kakade.&lt;/p&gt;
</description>
        <pubDate>Wed, 21 Aug 2019 00:00:00 -0700</pubDate>
        <link>/news/2019/08/21/workshop/</link>
        <guid isPermaLink="true">/news/2019/08/21/workshop/</guid>
      </item>
    
      <item>
        <title>Summer School on Foundations of Data Science</title>
        <description>&lt;center&gt;&lt;img src=&quot;http://ads-institute.uw.edu/images/school.jpg&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;a href=&quot;https://alecgt.github.io/adsi_summer/&quot;&gt;The ADSI Summer School on Foundations of Data Science&lt;/a&gt; was organized by U. Washington and U.W. Madison over 4.5 days (August 13-17, 2019) at the University of Washington in Seattle. The event gave a large and advanced introduction to fundamental aspects of data science, including stochastic optimization, convex optimization, convex geometry and sampling, computational imaging, deep generative models, fairness in machine learning, reinforcement learning and active machine learning. The format was mostly lectures accompanied with notes. They were generally organized by a first part covering basic concepts and a second part introducing present research with an emphasis on recent discoveries of fundamental principles. An interactive lab was also conducted in computational imaging.&lt;/p&gt;

&lt;p&gt;The target audience was graduate students and postdocs, with some knowledge of some of the fundamental areas of data science, but a desire to learn about other topics in the area. 
Lecturers included Paquette (U. Waterloo); Diakonikolas, Hardt (U.C. Berkeley); Lee, Jamieson, Oh (U. Washington); Nowak (U.W. Madison); Willett (U. Chicago); Agarwal (Microsoft Research). A poster session was also organised at which participants presented their research.&lt;/p&gt;

&lt;p&gt;The summer school was made possible by support from National Science Foundation. The program was organized by Dmitriy Drusvyatskiy and Zaid Harchaoui.&lt;/p&gt;

</description>
        <pubDate>Sat, 17 Aug 2019 00:00:00 -0700</pubDate>
        <link>/news/2019/08/17/summer-school/</link>
        <guid isPermaLink="true">/news/2019/08/17/summer-school/</guid>
      </item>
    
      <item>
        <title>Announcing the ADSI Workshop on Learning and Control</title>
        <description>&lt;p&gt;The ADSI faculty announce the organization of a workshop in August 2019 on the Algorithmic Foundations of Learning and Control. The workshop is geared towards researchers in computer science, control theory, statistics, and mathematics. It aims to bring together people from a diverse set of backgrounds who are interested in bridging the gap between reinforcement learning, control theory, and statistical learning.&lt;/p&gt;

&lt;p&gt;The workshop will feature lectures from distinguished speakers spanning these disciplines as well as open problem and discussion sessions. More details can be found on the workshop &lt;a href=&quot;https://ajwagen.github.io/adsi_learning_and_control/&quot;&gt;website&lt;/a&gt;. Researchers currently working in the area are encouraged to apply.&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Jun 2019 00:00:00 -0700</pubDate>
        <link>/news/2019/06/10/Workshop/</link>
        <guid isPermaLink="true">/news/2019/06/10/Workshop/</guid>
      </item>
    
  </channel>
</rss>
